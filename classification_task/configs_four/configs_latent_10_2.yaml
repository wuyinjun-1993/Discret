model:
  mlp:
    latent_size: 10
  transformer:
    latent_size: 10
    tf_latent_size: 10
    pretrained_model_path: "/data6/wuyinjun/cancer_data_four/logs/pretrain/pretrain_net_299"
    fix_pretrained_model: true
    depth: 6
    heads: 8
    attn_dropout: 0.1
    ff_dropout: 0.1
rl:
  dqn:
    mem_sample_size: 16
    replay_memory_capacity: 5000
    epsilon: 0.2
    epsilon_falloff: 0.9
    gamma: 0.999
    target_update: 20
  ppo:
    n_updates_per_iteration: 10
    clip: 0.1
    timesteps_per_batch: 5
    continue_act: false
    gamma: 0.999